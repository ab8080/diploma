{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPXB_XfXKV_K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M0eSRnDfK-4Z"
      },
      "outputs": [],
      "source": [
        "class BoundingBoxLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BoundingBoxLoss, self).__init__()\n",
        "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "\n",
        "        # Вычисляем потери только для координат ограничивающих рамок\n",
        "        loss = self.mse_loss(predictions, targets)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YlLGEZyyLGvW"
      },
      "outputs": [],
      "source": [
        "# Определение сверточного слоя с BatchNorm и LeakyReLU\n",
        "class ConvBNLeaky(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBNLeaky, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.leaky_relu(self.bn(self.conv(x)))\n",
        "\n",
        "# Определение остаточного блока\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = ConvBNLeaky(channels, channels // 2, 1, 1, 0)\n",
        "        self.conv2 = ConvBNLeaky(channels // 2, channels, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv2(self.conv1(x))\n",
        "\n",
        "# Основная архитектура YOLOv3\n",
        "class YOLOv3(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(YOLOv3, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.layer1 = ConvBNLeaky(3, 32, 3, 1, 1)\n",
        "        self.layer2 = ConvBNLeaky(32, 64, 3, 2, 1)\n",
        "        self.residual_block1 = ResidualBlock(64)\n",
        "\n",
        "        # Дополнительные слои\n",
        "        self.layer3 = ConvBNLeaky(64, 128, 3, 2, 1)\n",
        "        self.residual_block2 = ResidualBlock(128)\n",
        "        self.layer4 = ConvBNLeaky(128, 256, 3, 2, 1)\n",
        "        self.residual_block3 = ResidualBlock(256)\n",
        "        self.layer5 = ConvBNLeaky(256, 512, 3, 2, 1)\n",
        "        self.residual_block4 = ResidualBlock(512)\n",
        "        self.layer6 = ConvBNLeaky(512, 1024, 3, 2, 1)\n",
        "        self.residual_block5 = ResidualBlock(1024)\n",
        "\n",
        "        # Слои обнаружения\n",
        "        self.detection1 = nn.Conv2d(1024, 5 * num_classes, 1)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_conv = nn.Conv2d(1024, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.residual_block1(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.residual_block2(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.residual_block4(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.residual_block5(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)  # Применение глобального среднего пулинга\n",
        "        detection = self.final_conv(x)  # Применение конечного сверточного слоя\n",
        "        detection = detection.view(x.size(0), -1)  # Изменение формы тензора\n",
        "        return detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NKVY1pEPLU0g"
      },
      "outputs": [],
      "source": [
        "class YourDataset(Dataset):\n",
        "    def __init__(self, img_dir, ann_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.ann_dir = ann_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Получение списка имен файлов изображений\n",
        "        self.img_names = [img_name for img_name in os.listdir(img_dir) if img_name.endswith('.jpg')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        ann_path = os.path.join(self.ann_dir, img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "        # Загрузка изображения\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Загрузка аннотаций\n",
        "        annotations = self.load_annotations(ann_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, annotations\n",
        "\n",
        "    @staticmethod\n",
        "    def load_annotations(ann_path):\n",
        "        annotations = []\n",
        "        with open(ann_path, 'r') as file:\n",
        "            for line in file:\n",
        "                class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "                annotations.append([class_id, x_center, y_center, width, height])\n",
        "        return torch.tensor(annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cTUWU3dwLk9_"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLlbXGarMXsP",
        "outputId": "20c449fd-de8c-45c1-b784-c147896fa9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yPmMtAUFMwGl"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/small_dataset.zip\" \"/content/small_dataset.zip\"  # Копирование файла на локальный диск Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/small_dataset.zip\" -d \"/content/\"  # Распаковка содержимого архива"
      ],
      "metadata": {
        "id": "vkJY0ruH_pKV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pV0JwZmsL_ty"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Теперь пути к данным должны указывать на распакованные каталоги\n",
        "img_dir = '/content/test_images'  # Пример пути к изображениям для обучения\n",
        "ann_dir = '/content/test_annotations'  # Пример пути к аннотациям для обучения\n",
        "\n",
        "test_img_dir = '/content/test_test_images'  # Пример пути к изображениям для тестирования\n",
        "test_ann_dir = '/content/test_test_annotations'  # Пример пути к аннотациям для тестирования\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDvMh6QgPbIJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2WJQN4PM_X_",
        "outputId": "020e0934-b861-4a98-cbd3-23ee18451be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grc_passport_82_000181.jpg\n",
            "grc_passport_82_000235.jpg\n",
            "grc_passport_82_000301.jpg\n",
            "grc_passport_82_000355.jpg\n",
            "grc_passport_82_000361.jpg\n",
            "grc_passport_82_000385.jpg\n",
            "grc_passport_82_000391.jpg\n",
            "grc_passport_82_000427.jpg\n",
            "grc_passport_82_000439.jpg\n",
            "grc_passport_82_000451.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/test_test_images' | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "c4PPeoMENH1_"
      },
      "outputs": [],
      "source": [
        "# Создание модели\n",
        "model = YOLOv3(num_classes=1)\n",
        "\n",
        "# Проверка доступности CUDA\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Создание экземпляра функции потерь и оптимизатора\n",
        "criterion = BoundingBoxLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = YourDataset(img_dir, ann_dir, transform=transform)\n",
        "test_dataset = YourDataset(test_img_dir, test_ann_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W9lVkLu2acwD"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urttsGMzS2Ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NaY158alN9WD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2bb2d88d-ad7d-45ee-d6c3-22c3c91e8ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i'm inside\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([128, 1, 5])) that is different to the input size (torch.Size([128, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 0, Loss: 34326.9765625\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 1/10, Train MSE: 18714.888880411785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([54, 1, 5])) that is different to the input size (torch.Size([54, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Validation Loss: 1015.467632929484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56, 1, 5])) that is different to the input size (torch.Size([56, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i'm inside\n",
            "Epoch: 2, Batch: 0, Loss: 842.296630859375\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 2/10, Train MSE: 791.0879257444351\n",
            "Epoch 2/10, Validation Loss: 977.3410517374674\n",
            "i'm inside\n",
            "Epoch: 3, Batch: 0, Loss: 891.4882202148438\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 3/10, Train MSE: 769.8039894709511\n",
            "Epoch 3/10, Validation Loss: 778.7361602783203\n",
            "i'm inside\n",
            "Epoch: 4, Batch: 0, Loss: 781.0452880859375\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 4/10, Train MSE: 763.8532346695189\n",
            "Epoch 4/10, Validation Loss: 615.1361821492513\n",
            "i'm inside\n",
            "Epoch: 5, Batch: 0, Loss: 699.5086669921875\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 5/10, Train MSE: 760.2030101957776\n",
            "Epoch 5/10, Validation Loss: 928.0055885314941\n",
            "i'm inside\n",
            "Epoch: 6, Batch: 0, Loss: 668.186767578125\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 6/10, Train MSE: 762.2078290666852\n",
            "Epoch 6/10, Validation Loss: 780.5796019236246\n",
            "i'm inside\n",
            "Epoch: 7, Batch: 0, Loss: 805.267822265625\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 7/10, Train MSE: 760.9813828241257\n",
            "Epoch 7/10, Validation Loss: 773.3248895009359\n",
            "i'm inside\n",
            "Epoch: 8, Batch: 0, Loss: 675.3875732421875\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "Epoch 8/10, Train MSE: 758.919169592479\n",
            "Epoch 8/10, Validation Loss: 706.2076218922933\n",
            "i'm inside\n",
            "Epoch: 9, Batch: 0, Loss: 976.7347412109375\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n",
            "i'm inside\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c60cbfc97155>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i'm inside\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Цикл обучения\n",
        "num_epochs = 10  # Примерное количество эпох\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Переключение модели в режим обучения\n",
        "    train_mse = 0\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "        print(\"i'm inside\")\n",
        "        if torch.cuda.is_available():\n",
        "            images, targets = images.cuda(), targets.cuda()  # Перемещение данных на GPU, если она доступна\n",
        "        optimizer.zero_grad()  # Обнуление градиентов\n",
        "        outputs = model(images)  # Получение предсказаний модели\n",
        "        loss = criterion(outputs, targets)  # Вычисление потерь\n",
        "        train_mse += loss.item()  # Суммирование ошибки\n",
        "        loss.backward()  # Вычисление градиентов\n",
        "        optimizer.step()  # Обновление параметров модели\n",
        "\n",
        "        # Печать прогресса обучения\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item()}')\n",
        "\n",
        "    # Подсчет средней ошибки по эпохе\n",
        "    average_train_mse = train_mse / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train MSE: {average_train_mse}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()  # Переключение модели в режим валидации\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():  # Отключение вычисления градиентов\n",
        "        for images, targets in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images, targets = images.cuda(), targets.cuda()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Подсчет средней ошибки валидации по эпохе\n",
        "    average_val_loss = val_loss / len(test_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03w4EKGinszg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}